{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim.models as g\n",
    "from scipy import spatial\n",
    "import numpy as np\n",
    "import spacy \n",
    "import sent2vec\n",
    "from nltk.corpus import stopwords\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "Stoplist = set(stopwords.words('english'))\n",
    "start_alpha=0.01\n",
    "infer_epoch=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleanText(text):\n",
    "    cleanedText = []\n",
    "    doc = nlp(text)\n",
    "    for word in doc:\n",
    "        if word.text.lower() not in Stoplist and not word.is_punct:\n",
    "            cleanedText.append(word.lemma_)\n",
    "    return cleanedText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Similarity(text1,text2,model_name):\n",
    "    \n",
    "    text1 = cleanText(text1)\n",
    "    text2 = cleanText(text2)\n",
    "    \n",
    "    if model_name == 'doc2vec-wiki':\n",
    "        model = model1\n",
    "        vec1 = model.infer_vector(text1, alpha=start_alpha, steps=infer_epoch)\n",
    "        vec2 = model.infer_vector(text2, alpha=start_alpha, steps=infer_epoch)\n",
    "    elif model_name == 'doc2vec-news':\n",
    "        model = model2\n",
    "        vec1 = model.infer_vector(text1, alpha=start_alpha, steps=infer_epoch)\n",
    "        vec2 = model.infer_vector(text2, alpha=start_alpha, steps=infer_epoch)\n",
    "    elif model_name=='spacy':\n",
    "        model = model3\n",
    "        text1 = ' '.join(text1)\n",
    "        text2 = ' '.join(text2)\n",
    "        vec1 = model(text1).vector\n",
    "        vec2 = model(text2).vector\n",
    "    elif model_name == 'sent2vec-wiki':\n",
    "        model = model4\n",
    "        text1 = ' '.join(text1)\n",
    "        text2 = ' '.join(text2)\n",
    "        vec1 = model.embed_sentence(text1) \n",
    "        vec2 = model.embed_sentence(text2) \n",
    "    elif model_name == 'sent2vec-book':\n",
    "        model = model5\n",
    "        text1 = ' '.join(text1)\n",
    "        text2 = ' '.join(text2)\n",
    "        vec1 = model.embed_sentence(text1) \n",
    "        vec2 = model.embed_sentence(text2) \n",
    "    similarity = 1-spatial.distance.cosine(vec1,vec2)\n",
    "#     dis = np.linalg.norm(vec1,vec2)\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'data/short-with-different-similarity.csv'\n",
    "data = pd.read_csv(filename,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/eric/.local/lib/python3.6/site-packages/gensim/models/doc2vec.py:566: UserWarning: The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\n",
      "  warnings.warn(\"The parameter `iter` is deprecated, will be removed in 4.0.0, use `epochs` instead.\")\n",
      "/home/eric/.local/lib/python3.6/site-packages/gensim/models/doc2vec.py:570: UserWarning: The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\n",
      "  warnings.warn(\"The parameter `size` is deprecated, will be removed in 4.0.0, use `vector_size` instead.\")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'pre_modle/doc2vec/enwiki/doc2vec.bin'\n",
    "model1 = g.Doc2Vec.load(model_name)\n",
    "model_name = 'pre_modle/doc2vec/apnews_dbow/doc2vec.bin'\n",
    "model2 = g.Doc2Vec.load(model_name)\n",
    "model3 = spacy.load('en_core_web_md')\n",
    "model4 = sent2vec.Sent2vecModel()\n",
    "model_name4 = 'pre_modle/sent2vec/wiki_unigrams.bin'\n",
    "model4.load_model(model_name4)\n",
    "model5 = sent2vec.Sent2vecModel()\n",
    "model_name5 = 'pre_modle/sent2vec/torontobooks_unigrams.bin'\n",
    "model5.load_model(model_name5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['apnews-doc2vec'] = data.apply(lambda row:Similarity(row['text1'],row['text2'],'doc2vec-news'),axis=1)\n",
    "\n",
    "data['enwiki-doc2vec'] = data.apply(lambda row:Similarity(row['text1'],row['text2'],'doc2vec-wiki'),axis=1)\n",
    "\n",
    "data['spacy_model'] = data.apply(lambda row:Similarity(row['text1'],row['text2'],'spacy'),axis=1)\n",
    "\n",
    "data['sent2vec-wiki'] = data.apply(lambda row:Similarity(row['text1'],row['text2'],'sent2vec-wiki'),axis=1)\n",
    "\n",
    "data['sent2vec-book'] = data.apply(lambda row:Similarity(row['text1'],row['text2'],'sent2vec-book'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity(0-5)</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>apnews-doc2vec</th>\n",
       "      <th>enwiki-doc2vec</th>\n",
       "      <th>spacy_model</th>\n",
       "      <th>sent2vec-wiki</th>\n",
       "      <th>sent2vec-book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A plane is taking off.</td>\n",
       "      <td>An air plane is taking off.</td>\n",
       "      <td>0.940989</td>\n",
       "      <td>0.923832</td>\n",
       "      <td>0.913210</td>\n",
       "      <td>0.845999</td>\n",
       "      <td>0.832755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A person is throwing a cat on to the ceiling.</td>\n",
       "      <td>A person throws a cat on the ceiling.</td>\n",
       "      <td>0.995888</td>\n",
       "      <td>0.996983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The man is using a sledghammer to break the co...</td>\n",
       "      <td>A man breaks a slab of concrete that is lying ...</td>\n",
       "      <td>0.688162</td>\n",
       "      <td>0.735864</td>\n",
       "      <td>0.895027</td>\n",
       "      <td>0.670609</td>\n",
       "      <td>0.602399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.8</td>\n",
       "      <td>Asian markets hit 3-wk high on hopes of US deb...</td>\n",
       "      <td>Asian stocks hit three-week highs on hopes of ...</td>\n",
       "      <td>0.821375</td>\n",
       "      <td>0.875974</td>\n",
       "      <td>0.939680</td>\n",
       "      <td>0.849537</td>\n",
       "      <td>0.785482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Three feared dead after helicopter crashes int...</td>\n",
       "      <td>Three feared dead after helicopter pub crash</td>\n",
       "      <td>0.994929</td>\n",
       "      <td>0.996317</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The polar bear is sliding on the snow.</td>\n",
       "      <td>A polar bear is sliding across the snow.</td>\n",
       "      <td>0.910261</td>\n",
       "      <td>0.919652</td>\n",
       "      <td>0.968950</td>\n",
       "      <td>0.951160</td>\n",
       "      <td>0.954318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>A close-up of a sheep with its tongue hanging ...</td>\n",
       "      <td>Close up image of a sheep with it's tongue han...</td>\n",
       "      <td>0.925597</td>\n",
       "      <td>0.902960</td>\n",
       "      <td>0.917458</td>\n",
       "      <td>0.917675</td>\n",
       "      <td>0.895894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.8</td>\n",
       "      <td>A women holds a small baby while sitting on a ...</td>\n",
       "      <td>a woman sitting on a sofa holding a baby.</td>\n",
       "      <td>0.925848</td>\n",
       "      <td>0.922263</td>\n",
       "      <td>0.980937</td>\n",
       "      <td>0.970073</td>\n",
       "      <td>0.959568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.8</td>\n",
       "      <td>A little boy jumping from one chair to another.</td>\n",
       "      <td>A young boy jumping from one chair to another ...</td>\n",
       "      <td>0.847536</td>\n",
       "      <td>0.842760</td>\n",
       "      <td>0.962537</td>\n",
       "      <td>0.847316</td>\n",
       "      <td>0.831891</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4.8</td>\n",
       "      <td>A black dog running through water.</td>\n",
       "      <td>A black dog is running through some water.</td>\n",
       "      <td>0.994477</td>\n",
       "      <td>0.995500</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.2</td>\n",
       "      <td>Some men are playing guitars.</td>\n",
       "      <td>Three men are playing guitars and singing toge...</td>\n",
       "      <td>0.839239</td>\n",
       "      <td>0.853243</td>\n",
       "      <td>0.911301</td>\n",
       "      <td>0.795416</td>\n",
       "      <td>0.814547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.2</td>\n",
       "      <td>Time of the Season by the Zombies We are all v...</td>\n",
       "      <td>Joy to the World We are all vessels filled wit...</td>\n",
       "      <td>0.797461</td>\n",
       "      <td>0.759925</td>\n",
       "      <td>0.882604</td>\n",
       "      <td>0.709496</td>\n",
       "      <td>0.652493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>3.5</td>\n",
       "      <td>A large bird standing on a table picks up a pl...</td>\n",
       "      <td>A bird picks up a plastic cup containing a liq...</td>\n",
       "      <td>0.783729</td>\n",
       "      <td>0.757713</td>\n",
       "      <td>0.912135</td>\n",
       "      <td>0.662591</td>\n",
       "      <td>0.766513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>3.2</td>\n",
       "      <td>A person wearing a helmet rides a bike near a ...</td>\n",
       "      <td>A person wearing a bike helmet rides a bike on...</td>\n",
       "      <td>0.790095</td>\n",
       "      <td>0.785858</td>\n",
       "      <td>0.916381</td>\n",
       "      <td>0.811470</td>\n",
       "      <td>0.790841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.2</td>\n",
       "      <td>Black and white cows behind a fence.</td>\n",
       "      <td>Two black and white cows behind a metal gate a...</td>\n",
       "      <td>0.744293</td>\n",
       "      <td>0.789122</td>\n",
       "      <td>0.887430</td>\n",
       "      <td>0.632200</td>\n",
       "      <td>0.621743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.4</td>\n",
       "      <td>Two people paddling in a red canoe with trees ...</td>\n",
       "      <td>Two people padding in a yellow canoe down a ri...</td>\n",
       "      <td>0.817468</td>\n",
       "      <td>0.839694</td>\n",
       "      <td>0.953542</td>\n",
       "      <td>0.757257</td>\n",
       "      <td>0.780057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.4</td>\n",
       "      <td>A man wearing a t-shirt that says \"Gigolo\" sta...</td>\n",
       "      <td>A man wearing a shirt that says \"Gigolo\" is st...</td>\n",
       "      <td>0.740682</td>\n",
       "      <td>0.777298</td>\n",
       "      <td>0.911798</td>\n",
       "      <td>0.769993</td>\n",
       "      <td>0.764710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.4</td>\n",
       "      <td>Austrian found hoarding 56 stolen skulls in ho...</td>\n",
       "      <td>Stolen skulls found in home museum</td>\n",
       "      <td>0.778910</td>\n",
       "      <td>0.841550</td>\n",
       "      <td>0.902620</td>\n",
       "      <td>0.800105</td>\n",
       "      <td>0.816231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>3.0</td>\n",
       "      <td>A person is adding food in a pan.</td>\n",
       "      <td>A woman puts rice into a pan.</td>\n",
       "      <td>0.574960</td>\n",
       "      <td>0.652746</td>\n",
       "      <td>0.843121</td>\n",
       "      <td>0.621622</td>\n",
       "      <td>0.537884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>3.4</td>\n",
       "      <td>A man is swinging from a rope attached to the ...</td>\n",
       "      <td>A man is swinging on a rope.</td>\n",
       "      <td>0.866828</td>\n",
       "      <td>0.865132</td>\n",
       "      <td>0.891204</td>\n",
       "      <td>0.803823</td>\n",
       "      <td>0.800980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A close-up of an animal with a long face stand...</td>\n",
       "      <td>A close-up of a woman with black boots next to...</td>\n",
       "      <td>0.489700</td>\n",
       "      <td>0.499972</td>\n",
       "      <td>0.711492</td>\n",
       "      <td>0.306615</td>\n",
       "      <td>0.307971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.4</td>\n",
       "      <td>A group of river barges with trees in the back...</td>\n",
       "      <td>A young girl wearing a bike helmet with a bicy...</td>\n",
       "      <td>0.478968</td>\n",
       "      <td>0.420223</td>\n",
       "      <td>0.594910</td>\n",
       "      <td>0.285953</td>\n",
       "      <td>0.331318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A table and chairs are in a room with a pictur...</td>\n",
       "      <td>A school bus driving down a road with green tr...</td>\n",
       "      <td>0.314096</td>\n",
       "      <td>0.338167</td>\n",
       "      <td>0.555780</td>\n",
       "      <td>0.202215</td>\n",
       "      <td>0.307454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Two guys sit on a couch holding beers with a g...</td>\n",
       "      <td>Two women watching the street with their bikes...</td>\n",
       "      <td>0.325021</td>\n",
       "      <td>0.436538</td>\n",
       "      <td>0.773677</td>\n",
       "      <td>0.310161</td>\n",
       "      <td>0.309304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Former LAPD officer sought in Irvine slayings</td>\n",
       "      <td>Former CIA officer sentenced to 30 months in p...</td>\n",
       "      <td>0.440371</td>\n",
       "      <td>0.466887</td>\n",
       "      <td>0.754993</td>\n",
       "      <td>0.319972</td>\n",
       "      <td>0.414892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Australia to scrap soaring national debt ceiling</td>\n",
       "      <td>Australian PM insists no argument with Indonesia</td>\n",
       "      <td>0.417304</td>\n",
       "      <td>0.327523</td>\n",
       "      <td>0.524620</td>\n",
       "      <td>0.251309</td>\n",
       "      <td>0.183946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Mexico swears in president amid violent protests</td>\n",
       "      <td>Former New Mexico Gov. Richardson pressing Nor...</td>\n",
       "      <td>0.409221</td>\n",
       "      <td>0.417125</td>\n",
       "      <td>0.683370</td>\n",
       "      <td>0.245271</td>\n",
       "      <td>0.307794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Obama calls for international front against IS</td>\n",
       "      <td>Obama vows to save Iraqis stranded on mountain</td>\n",
       "      <td>0.378766</td>\n",
       "      <td>0.407365</td>\n",
       "      <td>0.637469</td>\n",
       "      <td>0.445072</td>\n",
       "      <td>0.306389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Thomas Cook accused of putting costs before cu...</td>\n",
       "      <td>University of Florida frat accused of spitting...</td>\n",
       "      <td>0.323099</td>\n",
       "      <td>0.393791</td>\n",
       "      <td>0.607955</td>\n",
       "      <td>0.325239</td>\n",
       "      <td>0.269181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Plastic toys are floating in water.</td>\n",
       "      <td>The ladies are performing a dance.</td>\n",
       "      <td>0.390700</td>\n",
       "      <td>0.434257</td>\n",
       "      <td>0.376576</td>\n",
       "      <td>0.040115</td>\n",
       "      <td>0.100952</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Similarity(0-5)                                              text1  \\\n",
       "0               5.0                             A plane is taking off.   \n",
       "1               5.0      A person is throwing a cat on to the ceiling.   \n",
       "2               5.0  The man is using a sledghammer to break the co...   \n",
       "3               4.8  Asian markets hit 3-wk high on hopes of US deb...   \n",
       "4               5.0  Three feared dead after helicopter crashes int...   \n",
       "5               5.0             The polar bear is sliding on the snow.   \n",
       "6               5.0  A close-up of a sheep with its tongue hanging ...   \n",
       "7               4.8  A women holds a small baby while sitting on a ...   \n",
       "8               4.8    A little boy jumping from one chair to another.   \n",
       "9               4.8                 A black dog running through water.   \n",
       "10              3.2                      Some men are playing guitars.   \n",
       "11              3.2  Time of the Season by the Zombies We are all v...   \n",
       "12              3.5  A large bird standing on a table picks up a pl...   \n",
       "13              3.2  A person wearing a helmet rides a bike near a ...   \n",
       "14              3.2               Black and white cows behind a fence.   \n",
       "15              3.4  Two people paddling in a red canoe with trees ...   \n",
       "16              3.4  A man wearing a t-shirt that says \"Gigolo\" sta...   \n",
       "17              3.4  Austrian found hoarding 56 stolen skulls in ho...   \n",
       "18              3.0                  A person is adding food in a pan.   \n",
       "19              3.4  A man is swinging from a rope attached to the ...   \n",
       "20              0.0  A close-up of an animal with a long face stand...   \n",
       "21              0.4  A group of river barges with trees in the back...   \n",
       "22              0.0  A table and chairs are in a room with a pictur...   \n",
       "23              0.0  Two guys sit on a couch holding beers with a g...   \n",
       "24              0.0      Former LAPD officer sought in Irvine slayings   \n",
       "25              0.0   Australia to scrap soaring national debt ceiling   \n",
       "26              0.0   Mexico swears in president amid violent protests   \n",
       "27              0.0     Obama calls for international front against IS   \n",
       "28              0.0  Thomas Cook accused of putting costs before cu...   \n",
       "29              0.0                Plastic toys are floating in water.   \n",
       "\n",
       "                                                text2  apnews-doc2vec  \\\n",
       "0                         An air plane is taking off.        0.940989   \n",
       "1               A person throws a cat on the ceiling.        0.995888   \n",
       "2   A man breaks a slab of concrete that is lying ...        0.688162   \n",
       "3   Asian stocks hit three-week highs on hopes of ...        0.821375   \n",
       "4        Three feared dead after helicopter pub crash        0.994929   \n",
       "5            A polar bear is sliding across the snow.        0.910261   \n",
       "6   Close up image of a sheep with it's tongue han...        0.925597   \n",
       "7           a woman sitting on a sofa holding a baby.        0.925848   \n",
       "8   A young boy jumping from one chair to another ...        0.847536   \n",
       "9          A black dog is running through some water.        0.994477   \n",
       "10  Three men are playing guitars and singing toge...        0.839239   \n",
       "11  Joy to the World We are all vessels filled wit...        0.797461   \n",
       "12  A bird picks up a plastic cup containing a liq...        0.783729   \n",
       "13  A person wearing a bike helmet rides a bike on...        0.790095   \n",
       "14  Two black and white cows behind a metal gate a...        0.744293   \n",
       "15  Two people padding in a yellow canoe down a ri...        0.817468   \n",
       "16  A man wearing a shirt that says \"Gigolo\" is st...        0.740682   \n",
       "17                 Stolen skulls found in home museum        0.778910   \n",
       "18                      A woman puts rice into a pan.        0.574960   \n",
       "19                       A man is swinging on a rope.        0.866828   \n",
       "20  A close-up of a woman with black boots next to...        0.489700   \n",
       "21  A young girl wearing a bike helmet with a bicy...        0.478968   \n",
       "22  A school bus driving down a road with green tr...        0.314096   \n",
       "23  Two women watching the street with their bikes...        0.325021   \n",
       "24  Former CIA officer sentenced to 30 months in p...        0.440371   \n",
       "25   Australian PM insists no argument with Indonesia        0.417304   \n",
       "26  Former New Mexico Gov. Richardson pressing Nor...        0.409221   \n",
       "27     Obama vows to save Iraqis stranded on mountain        0.378766   \n",
       "28  University of Florida frat accused of spitting...        0.323099   \n",
       "29                 The ladies are performing a dance.        0.390700   \n",
       "\n",
       "    enwiki-doc2vec  spacy_model  sent2vec-wiki  sent2vec-book  \n",
       "0         0.923832     0.913210       0.845999       0.832755  \n",
       "1         0.996983     1.000000       1.000000       1.000000  \n",
       "2         0.735864     0.895027       0.670609       0.602399  \n",
       "3         0.875974     0.939680       0.849537       0.785482  \n",
       "4         0.996317     1.000000       1.000000       1.000000  \n",
       "5         0.919652     0.968950       0.951160       0.954318  \n",
       "6         0.902960     0.917458       0.917675       0.895894  \n",
       "7         0.922263     0.980937       0.970073       0.959568  \n",
       "8         0.842760     0.962537       0.847316       0.831891  \n",
       "9         0.995500     1.000000       1.000000       1.000000  \n",
       "10        0.853243     0.911301       0.795416       0.814547  \n",
       "11        0.759925     0.882604       0.709496       0.652493  \n",
       "12        0.757713     0.912135       0.662591       0.766513  \n",
       "13        0.785858     0.916381       0.811470       0.790841  \n",
       "14        0.789122     0.887430       0.632200       0.621743  \n",
       "15        0.839694     0.953542       0.757257       0.780057  \n",
       "16        0.777298     0.911798       0.769993       0.764710  \n",
       "17        0.841550     0.902620       0.800105       0.816231  \n",
       "18        0.652746     0.843121       0.621622       0.537884  \n",
       "19        0.865132     0.891204       0.803823       0.800980  \n",
       "20        0.499972     0.711492       0.306615       0.307971  \n",
       "21        0.420223     0.594910       0.285953       0.331318  \n",
       "22        0.338167     0.555780       0.202215       0.307454  \n",
       "23        0.436538     0.773677       0.310161       0.309304  \n",
       "24        0.466887     0.754993       0.319972       0.414892  \n",
       "25        0.327523     0.524620       0.251309       0.183946  \n",
       "26        0.417125     0.683370       0.245271       0.307794  \n",
       "27        0.407365     0.637469       0.445072       0.306389  \n",
       "28        0.393791     0.607955       0.325239       0.269181  \n",
       "29        0.434257     0.376576       0.040115       0.100952  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion  for short sentence\n",
    "1. As we can see from comparing the similarity 'label' and predicted similarity values, the results of 5 models are quilt similar and all of them can roughly reflect the similarity between texts. \n",
    "\n",
    "2. More specifically, the differences between most similarity, rough similarity and no similarity are not very obvious when using `spacy` model, the similarity values are always higher than others. And `sent2vec` model have better performance in no similarity situation while wrose performance in most similarity situation than `doc2vec` model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename2 = 'data/midlength.csv'\n",
    "mid_data = pd.read_csv(filename2,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aquaman film</td>\n",
       "      <td>Aquaman is a 2018 American superhero film base...</td>\n",
       "      <td>Aquaman is a 2018 American superhero movie bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>War horse film</td>\n",
       "      <td>War Horse is a 2011 war drama film directed an...</td>\n",
       "      <td>\"War Horse\" is a 2011 war film produced by Ste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news cnn</td>\n",
       "      <td>France's beleaguered President Emmanuel Macron...</td>\n",
       "      <td>France’s troubled president, Emmanuel Macron, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news cnn</td>\n",
       "      <td>SoftBank is raising $23.5 billion from the IPO...</td>\n",
       "      <td>Softbank raised $23.5 billion from its initial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book</td>\n",
       "      <td>Winter is coming. Such is the stern motto of H...</td>\n",
       "      <td>winter is here. This is the grim motto of Hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>book</td>\n",
       "      <td>Larry Page and Sergey Brin started out as two ...</td>\n",
       "      <td>Larry Page and Sergey Brin were originally stu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                              text1  \\\n",
       "0    aquaman film  Aquaman is a 2018 American superhero film base...   \n",
       "1  War horse film  War Horse is a 2011 war drama film directed an...   \n",
       "2        news cnn  France's beleaguered President Emmanuel Macron...   \n",
       "3        news cnn  SoftBank is raising $23.5 billion from the IPO...   \n",
       "4            book  Winter is coming. Such is the stern motto of H...   \n",
       "5            book  Larry Page and Sergey Brin started out as two ...   \n",
       "\n",
       "                                               text2  \n",
       "0  Aquaman is a 2018 American superhero movie bas...  \n",
       "1  \"War Horse\" is a 2011 war film produced by Ste...  \n",
       "2  France’s troubled president, Emmanuel Macron, ...  \n",
       "3  Softbank raised $23.5 billion from its initial...  \n",
       "4  winter is here. This is the grim motto of Hous...  \n",
       "5  Larry Page and Sergey Brin were originally stu...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_data['apnews-doc2vec'] = mid_data.apply(lambda row:Similarity(row['text1'],row['text2'],'doc2vec-news'),axis=1)\n",
    "\n",
    "mid_data['enwiki-doc2vec'] = mid_data.apply(lambda row:Similarity(row['text1'],row['text2'],'doc2vec-wiki'),axis=1)\n",
    "\n",
    "mid_data['spacy_model'] = mid_data.apply(lambda row:Similarity(row['text1'],row['text2'],'spacy'),axis=1)\n",
    "\n",
    "mid_data['sent2vec-wiki'] = mid_data.apply(lambda row:Similarity(row['text1'],row['text2'],'sent2vec-wiki'),axis=1)\n",
    "\n",
    "mid_data['sent2vec-book'] = mid_data.apply(lambda row:Similarity(row['text1'],row['text2'],'sent2vec-book'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>apnews-doc2vec</th>\n",
       "      <th>enwiki-doc2vec</th>\n",
       "      <th>spacy_model</th>\n",
       "      <th>sent2vec-wiki</th>\n",
       "      <th>sent2vec-book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aquaman film</td>\n",
       "      <td>Aquaman is a 2018 American superhero film base...</td>\n",
       "      <td>Aquaman is a 2018 American superhero movie bas...</td>\n",
       "      <td>0.813662</td>\n",
       "      <td>0.808581</td>\n",
       "      <td>0.987220</td>\n",
       "      <td>0.949630</td>\n",
       "      <td>0.934225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>War horse film</td>\n",
       "      <td>War Horse is a 2011 war drama film directed an...</td>\n",
       "      <td>\"War Horse\" is a 2011 war film produced by Ste...</td>\n",
       "      <td>0.565123</td>\n",
       "      <td>0.626069</td>\n",
       "      <td>0.980515</td>\n",
       "      <td>0.930960</td>\n",
       "      <td>0.941416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news cnn</td>\n",
       "      <td>France's beleaguered President Emmanuel Macron...</td>\n",
       "      <td>France’s troubled president, Emmanuel Macron, ...</td>\n",
       "      <td>0.619763</td>\n",
       "      <td>0.749756</td>\n",
       "      <td>0.987991</td>\n",
       "      <td>0.901309</td>\n",
       "      <td>0.916684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>news cnn</td>\n",
       "      <td>SoftBank is raising $23.5 billion from the IPO...</td>\n",
       "      <td>Softbank raised $23.5 billion from its initial...</td>\n",
       "      <td>0.862888</td>\n",
       "      <td>0.794714</td>\n",
       "      <td>0.989073</td>\n",
       "      <td>0.881828</td>\n",
       "      <td>0.861980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>book</td>\n",
       "      <td>Winter is coming. Such is the stern motto of H...</td>\n",
       "      <td>winter is here. This is the grim motto of Hous...</td>\n",
       "      <td>0.646837</td>\n",
       "      <td>0.716216</td>\n",
       "      <td>0.985169</td>\n",
       "      <td>0.901795</td>\n",
       "      <td>0.929474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>book</td>\n",
       "      <td>Larry Page and Sergey Brin started out as two ...</td>\n",
       "      <td>Larry Page and Sergey Brin were originally stu...</td>\n",
       "      <td>0.876634</td>\n",
       "      <td>0.875314</td>\n",
       "      <td>0.996401</td>\n",
       "      <td>0.942708</td>\n",
       "      <td>0.945079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         category                                              text1  \\\n",
       "0    aquaman film  Aquaman is a 2018 American superhero film base...   \n",
       "1  War horse film  War Horse is a 2011 war drama film directed an...   \n",
       "2        news cnn  France's beleaguered President Emmanuel Macron...   \n",
       "3        news cnn  SoftBank is raising $23.5 billion from the IPO...   \n",
       "4            book  Winter is coming. Such is the stern motto of H...   \n",
       "5            book  Larry Page and Sergey Brin started out as two ...   \n",
       "\n",
       "                                               text2  apnews-doc2vec  \\\n",
       "0  Aquaman is a 2018 American superhero movie bas...        0.813662   \n",
       "1  \"War Horse\" is a 2011 war film produced by Ste...        0.565123   \n",
       "2  France’s troubled president, Emmanuel Macron, ...        0.619763   \n",
       "3  Softbank raised $23.5 billion from its initial...        0.862888   \n",
       "4  winter is here. This is the grim motto of Hous...        0.646837   \n",
       "5  Larry Page and Sergey Brin were originally stu...        0.876634   \n",
       "\n",
       "   enwiki-doc2vec  spacy_model  sent2vec-wiki  sent2vec-book  \n",
       "0        0.808581     0.987220       0.949630       0.934225  \n",
       "1        0.626069     0.980515       0.930960       0.941416  \n",
       "2        0.749756     0.987991       0.901309       0.916684  \n",
       "3        0.794714     0.989073       0.881828       0.861980  \n",
       "4        0.716216     0.985169       0.901795       0.929474  \n",
       "5        0.875314     0.996401       0.942708       0.945079  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mid_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99731445, 0.21581405, 0.15599056, 0.16480331, 0.134446  ,\n",
       "        0.08293127],\n",
       "       [0.21018738, 0.99729663, 0.13252205, 0.22369686, 0.04420083,\n",
       "        0.23202498],\n",
       "       [0.14947909, 0.13835289, 0.99754429, 0.21963757, 0.10716819,\n",
       "        0.16266316],\n",
       "       [0.17123395, 0.22618191, 0.21458954, 0.99747044, 0.10365105,\n",
       "        0.25678715],\n",
       "       [0.14392978, 0.046594  , 0.09751491, 0.11291826, 0.99778134,\n",
       "        0.19776569],\n",
       "       [0.08203812, 0.24202962, 0.15909469, 0.26074922, 0.19760226,\n",
       "        0.9978081 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(mid_data)\n",
    "doc_wiki_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        doc_wiki_similarity_matrix[i][j] = Similarity(mid_data['text1'][i],mid_data['text1'][j],'doc2vec-wiki')\n",
    "doc_wiki_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9968909 , 0.16280739, 0.14173245, 0.13735011, 0.16581725,\n",
       "        0.10709067],\n",
       "       [0.16241267, 0.99692965, 0.00544766, 0.16304564, 0.06182747,\n",
       "        0.04420014],\n",
       "       [0.14352804, 0.0083732 , 0.99613637, 0.19121552, 0.11910781,\n",
       "        0.03413794],\n",
       "       [0.1363714 , 0.16411805, 0.1920106 , 0.99692279, 0.04693313,\n",
       "        0.10878582],\n",
       "       [0.16268101, 0.05389598, 0.12622261, 0.04090607, 0.99652582,\n",
       "        0.0745259 ],\n",
       "       [0.11337509, 0.04595864, 0.03855558, 0.11901323, 0.07967521,\n",
       "        0.99667794]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(mid_data)\n",
    "doc_news_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        doc_news_similarity_matrix[i][j] = Similarity(mid_data['text1'][i],mid_data['text1'][j],'doc2vec-news')\n",
    "doc_news_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.92772526, 0.72999591, 0.66184801, 0.81031102,\n",
       "        0.79786593],\n",
       "       [0.92772526, 1.        , 0.75245023, 0.69731605, 0.80058205,\n",
       "        0.82682389],\n",
       "       [0.72999591, 0.75245023, 1.        , 0.79818058, 0.77867723,\n",
       "        0.88094389],\n",
       "       [0.66184801, 0.69731605, 0.79818058, 1.        , 0.61613399,\n",
       "        0.83382994],\n",
       "       [0.81031102, 0.80058205, 0.77867723, 0.61613399, 1.        ,\n",
       "        0.76698291],\n",
       "       [0.79786593, 0.82682389, 0.88094389, 0.83382994, 0.76698291,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(mid_data)\n",
    "Spacy_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        Spacy_similarity_matrix[i][j] = Similarity(mid_data['text1'][i],mid_data['text1'][j],'spacy')\n",
    "Spacy_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.61014009, 0.38175514, 0.27626565, 0.46372506,\n",
       "        0.44519082],\n",
       "       [0.61014009, 1.        , 0.35510904, 0.29533574, 0.48252979,\n",
       "        0.45985863],\n",
       "       [0.38175514, 0.35510904, 1.        , 0.33894649, 0.34196723,\n",
       "        0.38124728],\n",
       "       [0.27626565, 0.29533574, 0.33894649, 1.        , 0.24845861,\n",
       "        0.40929586],\n",
       "       [0.46372506, 0.48252979, 0.34196723, 0.24845861, 1.        ,\n",
       "        0.4164612 ],\n",
       "       [0.44519082, 0.45985863, 0.38124728, 0.40929586, 0.4164612 ,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(mid_data)\n",
    "sent2vec_wiki_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        sent2vec_wiki_similarity_matrix[i][j] = Similarity(mid_data['text1'][i],mid_data['text1'][j],'sent2vec-wiki')\n",
    "sent2vec_wiki_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.66493732, 0.40956378, 0.31983775, 0.45252928,\n",
       "        0.52453613],\n",
       "       [0.66493732, 1.        , 0.43538448, 0.32854068, 0.43098626,\n",
       "        0.51314557],\n",
       "       [0.40956378, 0.43538448, 1.        , 0.31168911, 0.3744334 ,\n",
       "        0.44613749],\n",
       "       [0.31983775, 0.32854068, 0.31168911, 1.        , 0.24469551,\n",
       "        0.38942701],\n",
       "       [0.45252928, 0.43098626, 0.3744334 , 0.24469551, 1.        ,\n",
       "        0.39667109],\n",
       "       [0.52453613, 0.51314557, 0.44613749, 0.38942701, 0.39667109,\n",
       "        1.        ]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(mid_data)\n",
    "sent2vec_book_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        sent2vec_book_similarity_matrix[i][j] = Similarity(mid_data['text1'][i],mid_data['text1'][j],'sent2vec-book')\n",
    "sent2vec_book_similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion for paragraph(mid length)\n",
    "1. Obviously, `sent2vec` and `spacy` models perform better than `doc2vec` since they have high values for two most similar texts.\n",
    "\n",
    "2. As we can see results of similarity between totally different texts, `spacy` model did the worst performance since it has high similarity value. additionly, `doc2vec` performs better than `sent2vec` since it has very low value for totally different text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename3 = 'data/large.csv'\n",
    "large_data = pd.read_csv(filename3,header=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aquaman film</td>\n",
       "      <td>In 1912, a teenage boy named Albert Narracott ...</td>\n",
       "      <td>In 1912, a teenage boy named Jeremy Irvine fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book</td>\n",
       "      <td>Winter is coming. Such is the stern motto of H...</td>\n",
       "      <td>winter is here. This is the grim motto of Hous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news healthy</td>\n",
       "      <td>Most US adults have not gotten a flu shot this...</td>\n",
       "      <td>According to a new survey by the University of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Similarity                                              text1  \\\n",
       "0  aquaman film  In 1912, a teenage boy named Albert Narracott ...   \n",
       "1         Book   Winter is coming. Such is the stern motto of H...   \n",
       "2  news healthy  Most US adults have not gotten a flu shot this...   \n",
       "\n",
       "                                               text2  \n",
       "0  In 1912, a teenage boy named Jeremy Irvine fro...  \n",
       "1  winter is here. This is the grim motto of Hous...  \n",
       "2  According to a new survey by the University of...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_data['apnews-doc2vec'] = large_data.apply(lambda row:Similarity(row['text1'],row['text2'],'doc2vec-news'),axis=1)\n",
    "\n",
    "large_data['enwiki-doc2vec'] = large_data.apply(lambda row:Similarity(row['text1'],row['text2'],'doc2vec-wiki'),axis=1)\n",
    "\n",
    "large_data['spacy_model'] = large_data.apply(lambda row:Similarity(row['text1'],row['text2'],'spacy'),axis=1)\n",
    "\n",
    "large_data['sent2vec-wiki'] = large_data.apply(lambda row:Similarity(row['text1'],row['text2'],'sent2vec-wiki'),axis=1)\n",
    "\n",
    "large_data['sent2vec-book'] = large_data.apply(lambda row:Similarity(row['text1'],row['text2'],'sent2vec-book'),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Similarity</th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>apnews-doc2vec</th>\n",
       "      <th>enwiki-doc2vec</th>\n",
       "      <th>spacy_model</th>\n",
       "      <th>sent2vec-wiki</th>\n",
       "      <th>sent2vec-book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aquaman film</td>\n",
       "      <td>In 1912, a teenage boy named Albert Narracott ...</td>\n",
       "      <td>In 1912, a teenage boy named Jeremy Irvine fro...</td>\n",
       "      <td>0.750486</td>\n",
       "      <td>0.787303</td>\n",
       "      <td>0.998505</td>\n",
       "      <td>0.891484</td>\n",
       "      <td>0.883031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Book</td>\n",
       "      <td>Winter is coming. Such is the stern motto of H...</td>\n",
       "      <td>winter is here. This is the grim motto of Hous...</td>\n",
       "      <td>0.685813</td>\n",
       "      <td>0.693092</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>0.901795</td>\n",
       "      <td>0.929474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>news healthy</td>\n",
       "      <td>Most US adults have not gotten a flu shot this...</td>\n",
       "      <td>According to a new survey by the University of...</td>\n",
       "      <td>0.746555</td>\n",
       "      <td>0.818245</td>\n",
       "      <td>0.995050</td>\n",
       "      <td>0.798488</td>\n",
       "      <td>0.774948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Similarity                                              text1  \\\n",
       "0  aquaman film  In 1912, a teenage boy named Albert Narracott ...   \n",
       "1         Book   Winter is coming. Such is the stern motto of H...   \n",
       "2  news healthy  Most US adults have not gotten a flu shot this...   \n",
       "\n",
       "                                               text2  apnews-doc2vec  \\\n",
       "0  In 1912, a teenage boy named Jeremy Irvine fro...        0.750486   \n",
       "1  winter is here. This is the grim motto of Hous...        0.685813   \n",
       "2  According to a new survey by the University of...        0.746555   \n",
       "\n",
       "   enwiki-doc2vec  spacy_model  sent2vec-wiki  sent2vec-book  \n",
       "0        0.787303     0.998505       0.891484       0.883031  \n",
       "1        0.693092     0.989655       0.901795       0.929474  \n",
       "2        0.818245     0.995050       0.798488       0.774948  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "large_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9938013 , 0.09592321, 0.06730756],\n",
       "       [0.09503138, 0.99717194, 0.17279464],\n",
       "       [0.06566888, 0.16566174, 0.99778038]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(large_data)\n",
    "doc_news_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        doc_news_similarity_matrix[i][j] = Similarity(large_data['text1'][i],large_data['text1'][j],'doc2vec-news')\n",
    "doc_news_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.99862653, 0.25673881, 0.19791135],\n",
       "       [0.25330362, 0.99781716, 0.19183794],\n",
       "       [0.19752719, 0.19131333, 0.99852228]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(large_data)\n",
    "doc_wiki_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        doc_wiki_similarity_matrix[i][j] = Similarity(large_data['text1'][i],large_data['text1'][j],'doc2vec-wiki')\n",
    "doc_wiki_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.88152868, 0.79017919],\n",
       "       [0.88152868, 1.        , 0.70845801],\n",
       "       [0.79017919, 0.70845801, 1.        ]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(large_data)\n",
    "Spacy_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        Spacy_similarity_matrix[i][j] = Similarity(large_data['text1'][i],large_data['text1'][j],'spacy')\n",
    "Spacy_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.5105859 , 0.32040313],\n",
       "       [0.5105859 , 1.        , 0.29384309],\n",
       "       [0.32040313, 0.29384309, 1.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(large_data)\n",
    "sent2vec_book_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        sent2vec_book_similarity_matrix[i][j] = Similarity(large_data['text1'][i],large_data['text1'][j],'sent2vec-book')\n",
    "sent2vec_book_similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.51544517, 0.32921278],\n",
       "       [0.51544517, 1.        , 0.27732709],\n",
       "       [0.32921278, 0.27732709, 1.        ]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "length = len(large_data)\n",
    "sent2vec_wiki_similarity_matrix = np.zeros([length,length])\n",
    "for i in range(length):\n",
    "    for j in range(length):\n",
    "        sent2vec_wiki_similarity_matrix[i][j] = Similarity(large_data['text1'][i],large_data['text1'][j],'sent2vec-wiki')\n",
    "sent2vec_wiki_similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion for document(large length)\n",
    "1. As we can see results of similarity between totally different texts, the results are quilt similar with mid length.  `spacy` model did the worst performance since it has high similarity value. additionly, `doc2vec` has a very well performance when the text are large!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final decision\n",
    "I prefer to use `sent2vec` model in our project since it works well in short and mid length situation. Also, we usually have short and totally different texts in our project and `sent2vec` model is the most suitable model among three models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
